{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.999505</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>1.999703</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.999901</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>1.999990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.999999</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.998985</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>9.313226e-10</td>\n",
       "      <td>2.999391</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>4.656613e-10</td>\n",
       "      <td>2.999797</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>2.999980</td>\n",
       "      <td>...</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999998</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.998061</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>9.313226e-10</td>\n",
       "      <td>3.998836</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>3.999612</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>6.984919e-10</td>\n",
       "      <td>3.999961</td>\n",
       "      <td>...</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.999996</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1             2         3       4             5         6    \\\n",
       "0  1.000000  1294.0  0.000000e+00  1.000000  1294.0  0.000000e+00  1.000000   \n",
       "1  1.000000  1514.0  0.000000e+00  1.000000  1514.0  0.000000e+00  1.000000   \n",
       "2  1.999505  1294.0  6.984919e-10  1.999703  1294.0  2.328306e-10  1.999901   \n",
       "3  2.998985  1294.0  9.313226e-10  2.999391  1294.0  4.656613e-10  2.999797   \n",
       "4  3.998061  1294.0  9.313226e-10  3.998836  1294.0  2.328306e-10  3.999612   \n",
       "\n",
       "      7             8         9    ...           105  106  107       108  \\\n",
       "0  1294.0  0.000000e+00  1.000000  ...  0.000000e+00  0.0  0.0  1.000000   \n",
       "1  1514.0  0.000000e+00  1.000000  ...  0.000000e+00  0.0  0.0  1.000000   \n",
       "2  1294.0  6.984919e-10  1.999990  ...  0.000000e+00  0.0  0.0  1.999999   \n",
       "3  1294.0  6.984919e-10  2.999980  ...  6.984919e-10  0.0  0.0  2.999998   \n",
       "4  1294.0  6.984919e-10  3.999961  ...  2.328306e-10  0.0  0.0  3.999996   \n",
       "\n",
       "      109       110     111           112  113  114  \n",
       "0  1294.0  0.000000  1294.0  0.000000e+00  0.0  0.0  \n",
       "1  1514.0  0.000000  1514.0  0.000000e+00  0.0  0.0  \n",
       "2  1294.0  0.000000  1294.0  0.000000e+00  0.0  0.0  \n",
       "3  1294.0  0.000015  1294.0  2.328306e-10  0.0  0.0  \n",
       "4  1294.0  0.000000  1294.0  0.000000e+00  0.0  0.0  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2504267 entries, 0 to 2504266\n",
      "Columns: 115 entries, 0 to 114\n",
      "dtypes: float64(115)\n",
      "memory usage: 2.1 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.161843e+02</td>\n",
       "      <td>1.263429e+03</td>\n",
       "      <td>1.629564e+05</td>\n",
       "      <td>5.206959e+02</td>\n",
       "      <td>1.263908e+03</td>\n",
       "      <td>1.624291e+05</td>\n",
       "      <td>1.542137e+03</td>\n",
       "      <td>1.264399e+03</td>\n",
       "      <td>1.618282e+05</td>\n",
       "      <td>1.508207e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.618792e+05</td>\n",
       "      <td>-2.279080e-03</td>\n",
       "      <td>-7.277519e-07</td>\n",
       "      <td>2.433348e+04</td>\n",
       "      <td>1.264685e+03</td>\n",
       "      <td>3.848150e+02</td>\n",
       "      <td>1.319794e+03</td>\n",
       "      <td>1.617353e+05</td>\n",
       "      <td>-2.131455e-03</td>\n",
       "      <td>-5.309278e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.261311e+02</td>\n",
       "      <td>2.731945e+02</td>\n",
       "      <td>4.387131e+04</td>\n",
       "      <td>2.018029e+02</td>\n",
       "      <td>2.730516e+02</td>\n",
       "      <td>4.250538e+04</td>\n",
       "      <td>5.917664e+02</td>\n",
       "      <td>2.729755e+02</td>\n",
       "      <td>4.140203e+04</td>\n",
       "      <td>5.965275e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.570896e+04</td>\n",
       "      <td>1.849400e+00</td>\n",
       "      <td>6.071145e-04</td>\n",
       "      <td>6.679195e+03</td>\n",
       "      <td>2.771983e+02</td>\n",
       "      <td>1.050558e+02</td>\n",
       "      <td>7.498082e+01</td>\n",
       "      <td>4.563698e+04</td>\n",
       "      <td>1.538249e+00</td>\n",
       "      <td>5.666412e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.464452e+03</td>\n",
       "      <td>-4.688243e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.329919e+02</td>\n",
       "      <td>-2.887023e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.893583e+02</td>\n",
       "      <td>1.302018e+03</td>\n",
       "      <td>1.490105e+05</td>\n",
       "      <td>3.071747e+02</td>\n",
       "      <td>1.301232e+03</td>\n",
       "      <td>1.466209e+05</td>\n",
       "      <td>8.890711e+02</td>\n",
       "      <td>1.297967e+03</td>\n",
       "      <td>1.435192e+05</td>\n",
       "      <td>8.741032e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.793071e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.347740e+04</td>\n",
       "      <td>1.335240e+03</td>\n",
       "      <td>4.248047e+02</td>\n",
       "      <td>1.335240e+03</td>\n",
       "      <td>1.804590e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.604483e+02</td>\n",
       "      <td>1.328082e+03</td>\n",
       "      <td>1.727128e+05</td>\n",
       "      <td>6.178137e+02</td>\n",
       "      <td>1.331693e+03</td>\n",
       "      <td>1.754399e+05</td>\n",
       "      <td>1.921768e+03</td>\n",
       "      <td>1.336063e+03</td>\n",
       "      <td>1.789780e+05</td>\n",
       "      <td>1.945002e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.809940e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.763519e+04</td>\n",
       "      <td>1.340819e+03</td>\n",
       "      <td>4.254162e+02</td>\n",
       "      <td>1.340819e+03</td>\n",
       "      <td>1.809789e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.041041e+02</td>\n",
       "      <td>1.342751e+03</td>\n",
       "      <td>1.882200e+05</td>\n",
       "      <td>6.662270e+02</td>\n",
       "      <td>1.342305e+03</td>\n",
       "      <td>1.863478e+05</td>\n",
       "      <td>1.974742e+03</td>\n",
       "      <td>1.341165e+03</td>\n",
       "      <td>1.843493e+05</td>\n",
       "      <td>1.964070e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.821485e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.802381e+04</td>\n",
       "      <td>1.341263e+03</td>\n",
       "      <td>4.259399e+02</td>\n",
       "      <td>1.341263e+03</td>\n",
       "      <td>1.814248e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.365877e+02</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>4.942291e+05</td>\n",
       "      <td>8.073135e+02</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>4.948259e+05</td>\n",
       "      <td>2.124893e+03</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>4.953075e+05</td>\n",
       "      <td>1.983936e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.257562e+05</td>\n",
       "      <td>7.038125e+01</td>\n",
       "      <td>8.482200e-02</td>\n",
       "      <td>3.091260e+04</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>6.525000e+02</td>\n",
       "      <td>1.514000e+03</td>\n",
       "      <td>4.257562e+05</td>\n",
       "      <td>3.335587e+02</td>\n",
       "      <td>1.560442e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06   \n",
       "mean   3.161843e+02  1.263429e+03  1.629564e+05  5.206959e+02  1.263908e+03   \n",
       "std    1.261311e+02  2.731945e+02  4.387131e+04  2.018029e+02  2.730516e+02   \n",
       "min    1.000000e+00  6.000000e+01  0.000000e+00  1.000000e+00  6.000000e+01   \n",
       "25%    1.893583e+02  1.302018e+03  1.490105e+05  3.071747e+02  1.301232e+03   \n",
       "50%    3.604483e+02  1.328082e+03  1.727128e+05  6.178137e+02  1.331693e+03   \n",
       "75%    4.041041e+02  1.342751e+03  1.882200e+05  6.662270e+02  1.342305e+03   \n",
       "max    5.365877e+02  1.514000e+03  4.942291e+05  8.073135e+02  1.514000e+03   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06   \n",
       "mean   1.624291e+05  1.542137e+03  1.264399e+03  1.618282e+05  1.508207e+04   \n",
       "std    4.250538e+04  5.917664e+02  2.729755e+02  4.140203e+04  5.965275e+03   \n",
       "min    0.000000e+00  1.000000e+00  6.000000e+01  0.000000e+00  1.000000e+00   \n",
       "25%    1.466209e+05  8.890711e+02  1.297967e+03  1.435192e+05  8.741032e+03   \n",
       "50%    1.754399e+05  1.921768e+03  1.336063e+03  1.789780e+05  1.945002e+04   \n",
       "75%    1.863478e+05  1.974742e+03  1.341165e+03  1.843493e+05  1.964070e+04   \n",
       "max    4.948259e+05  2.124893e+03  1.514000e+03  4.953075e+05  1.983936e+04   \n",
       "\n",
       "       ...           105           106           107           108  \\\n",
       "count  ...  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06   \n",
       "mean   ...  1.618792e+05 -2.279080e-03 -7.277519e-07  2.433348e+04   \n",
       "std    ...  4.570896e+04  1.849400e+00  6.071145e-04  6.679195e+03   \n",
       "min    ...  0.000000e+00 -1.464452e+03 -4.688243e-01  1.000000e+00   \n",
       "25%    ...  1.793071e+05  0.000000e+00  0.000000e+00  2.347740e+04   \n",
       "50%    ...  1.809940e+05  0.000000e+00  0.000000e+00  2.763519e+04   \n",
       "75%    ...  1.821485e+05  0.000000e+00  0.000000e+00  2.802381e+04   \n",
       "max    ...  4.257562e+05  7.038125e+01  8.482200e-02  3.091260e+04   \n",
       "\n",
       "                109           110           111           112           113  \\\n",
       "count  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06  2.504267e+06   \n",
       "mean   1.264685e+03  3.848150e+02  1.319794e+03  1.617353e+05 -2.131455e-03   \n",
       "std    2.771983e+02  1.050558e+02  7.498082e+01  4.563698e+04  1.538249e+00   \n",
       "min    6.000000e+01  0.000000e+00  6.000000e+01  0.000000e+00 -8.329919e+02   \n",
       "25%    1.335240e+03  4.248047e+02  1.335240e+03  1.804590e+05  0.000000e+00   \n",
       "50%    1.340819e+03  4.254162e+02  1.340819e+03  1.809789e+05  0.000000e+00   \n",
       "75%    1.341263e+03  4.259399e+02  1.341263e+03  1.814248e+05  0.000000e+00   \n",
       "max    1.514000e+03  6.525000e+02  1.514000e+03  4.257562e+05  3.335587e+02   \n",
       "\n",
       "                114  \n",
       "count  2.504267e+06  \n",
       "mean  -5.309278e-07  \n",
       "std    5.666412e-04  \n",
       "min   -2.887023e-01  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    1.560442e-01  \n",
       "\n",
       "[8 rows x 115 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "# gathering the dataset\n",
    "\n",
    "PATH = \"arp_mitm\"\n",
    "\n",
    "FILE = \"ARP MitM_dataset-002.csv\"\n",
    "L_FILE = \"ARP MitM_labels.csv\"\n",
    "\n",
    "csv_path = os.path.join(PATH, FILE)\n",
    "dataset = pd.read_csv(csv_path, header=None)  \n",
    "\n",
    "display(dataset.head())\n",
    "display(dataset.info())\n",
    "display(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    x\n",
       "0           1  0.0\n",
       "1           2  0.0\n",
       "2           3  0.0\n",
       "3           4  0.0\n",
       "4           5  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2504267 entries, 0 to 2504266\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   x           float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 38.2 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>2.504267e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.252134e+06</td>\n",
       "      <td>4.573282e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.229198e+05</td>\n",
       "      <td>4.981759e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.260675e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.252134e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.878200e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.504267e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             x\n",
       "count  2.504267e+06  2.504267e+06\n",
       "mean   1.252134e+06  4.573282e-01\n",
       "std    7.229198e+05  4.981759e-01\n",
       "min    1.000000e+00  0.000000e+00\n",
       "25%    6.260675e+05  0.000000e+00\n",
       "50%    1.252134e+06  0.000000e+00\n",
       "75%    1.878200e+06  1.000000e+00\n",
       "max    2.504267e+06  1.000000e+00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gathering classified output data for dataset\n",
    "\n",
    "L_csv_path = os.path.join(PATH, L_FILE)\n",
    "dataset_L = pd.read_csv(L_csv_path, dtype={\"\": int, \"x\": 'float64'})  \n",
    "\n",
    "display(dataset_L.head())\n",
    "display(dataset_L.info())\n",
    "display(dataset_L.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO FEATURE SELECTION\n",
    "# gathering testing and training data\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset, dataset_L.drop('Unnamed: 0', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=11, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NO FEATURE SELECTION\n",
    "# running logistic regression and training the model using fit with the training data\n",
    "logreg = LogisticRegression(multi_class='auto', solver='lbfgs', n_jobs=11)\n",
    "logreg.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO FEATURE SELECTION\n",
    "# predicting the training and test data\n",
    "y_tr_pred = logreg.predict(x_train)\n",
    "y_pred = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE =  0.45743158343094453\n",
      "Testing MSE =  0.4570181785655529\n"
     ]
    }
   ],
   "source": [
    "# NO FEATURE SELECTION\n",
    "# finding training and testing mse for the predictions found in the previous lines of code\n",
    "print(\"Training MSE = \", mse(y_tr_pred,y_train))\n",
    "print(\"Testing MSE = \", mse(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING DATA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARSHIT\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "not malicous       0.54      1.00      0.70   1019052\n",
      "    malicous       0.00      0.00      0.00    859148\n",
      "\n",
      "    accuracy                           0.54   1878200\n",
      "   macro avg       0.27      0.50      0.35   1878200\n",
      "weighted avg       0.29      0.54      0.38   1878200\n",
      "\n",
      "0.5425684165690555\n",
      "\n",
      "TEST DATA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not malicous       0.54      1.00      0.70    339943\n",
      "    malicous       0.00      0.00      0.00    286124\n",
      "\n",
      "    accuracy                           0.54    626067\n",
      "   macro avg       0.27      0.50      0.35    626067\n",
      "weighted avg       0.29      0.54      0.38    626067\n",
      "\n",
      "0.5429818214344471\n"
     ]
    }
   ],
   "source": [
    "# NO FEATURE SELECTION\n",
    "# finding the classification reports and accuracy scores for the training and testing datasets\n",
    "print(\"\\nTRAINING DATA:\")\n",
    "print(classification_report(y_train, y_tr_pred, target_names=['not malicous', 'malicous']))\n",
    "print(metrics.accuracy_score(y_train, y_tr_pred))\n",
    "\n",
    "print(\"\\nTEST DATA:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['not malicous', 'malicous']))\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0's and 1's in y_train dataset:\n",
      "0.0    1019052\n",
      "1.0     859148\n",
      "Name: x, dtype: int64\n",
      "\n",
      "CONFUSION MATRIX FOR TRAINING SET: \n",
      " [[1019052       0]\n",
      " [ 859148       0]]\n",
      "\n",
      "Number of 0's and 1's in y_test dataset:\n",
      "0.0    339943\n",
      "1.0    286124\n",
      "Name: x, dtype: int64\n",
      "\n",
      "CONFUSION MATRIX FOR TESTING SET: \n",
      " [[339943      0]\n",
      " [286124      0]]\n"
     ]
    }
   ],
   "source": [
    "# NO FEATURE SELECTION\n",
    "# confusion matrices for training and testing set\n",
    "print(\"Number of 0's and 1's in y_train dataset:\")\n",
    "print(y_train['x'].value_counts())\n",
    "print(\"\\nCONFUSION MATRIX FOR TRAINING SET: \\n {}\".format(confusion_matrix(y_train, y_tr_pred)))\n",
    "\n",
    "print(\"\\nNumber of 0's and 1's in y_test dataset:\")\n",
    "print(y_test['x'].value_counts())\n",
    "print(\"\\nCONFUSION MATRIX FOR TESTING SET: \\n {}\".format(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT K BEST FEATURE SELECTION\n",
    "# gathering testing and training data\n",
    "\n",
    "feature_list_skb=[12, 13, 27, 28, 63, 56, 77, 88, 108, 101]\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(dataset.iloc[:,feature_list_skb], dataset_L.drop('Unnamed: 0', axis=1), random_state=2, stratify=dataset_L.drop('Unnamed: 0', axis=1), test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000000.0, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='ovr', n_jobs=11, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part g) fine tuning\n",
    "\n",
    "# SELECT K BEST FEATURE SELECTION\n",
    "# running logistic regression and training the model using fit with the training data\n",
    "\n",
    "# MODIFIED \"C\" OR INVERSE REGULARIZATION STRENGTH\n",
    "\n",
    "logreg2 = LogisticRegression(multi_class='ovr', solver='lbfgs', n_jobs=11, C=10000000.0)\n",
    "\n",
    "logreg2.fit(x2_train, y2_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT K BEST FEATURE SELECTION\n",
    "# predicting the training and test data\n",
    "\n",
    "y2_tr_pred = logreg2.predict(x2_train)\n",
    "y2_pred = logreg2.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE =  0.009392772173563033\n",
      "Testing MSE =  0.009332866929577825\n"
     ]
    }
   ],
   "source": [
    "# part h) training mse and test mse\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "# SELECT K BEST FEATURE SELECTION\n",
    "# finding training and testing mse for the predictions found in the previous lines of code\n",
    "\n",
    "print(\"Training MSE = \", mse(y2_tr_pred,y2_train))\n",
    "print(\"Testing MSE = \", mse(y2_pred,y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING DATA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not malicous       0.99      0.99      0.99    679497\n",
      "    malicous       0.99      0.99      0.99    572636\n",
      "\n",
      "    accuracy                           0.99   1252133\n",
      "   macro avg       0.99      0.99      0.99   1252133\n",
      "weighted avg       0.99      0.99      0.99   1252133\n",
      "\n",
      "0.990607227826437\n",
      "\n",
      "TEST DATA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not malicous       0.99      0.99      0.99    679498\n",
      "    malicous       0.99      0.99      0.99    572636\n",
      "\n",
      "    accuracy                           0.99   1252134\n",
      "   macro avg       0.99      0.99      0.99   1252134\n",
      "weighted avg       0.99      0.99      0.99   1252134\n",
      "\n",
      "0.9906671330704222\n"
     ]
    }
   ],
   "source": [
    "# part h) accuracy scores\n",
    "\n",
    "# SELECT K BEST FEATURE SELECTION\n",
    "# finding the classification reports and accuracy scores for the training and testing datasets\n",
    "\n",
    "print(\"\\nTRAINING DATA:\")\n",
    "print(classification_report(y2_train, y2_tr_pred, target_names=['not malicous', 'malicous']))\n",
    "print(metrics.accuracy_score(y2_train, y2_tr_pred))\n",
    "\n",
    "print(\"\\nTEST DATA:\")\n",
    "print(classification_report(y2_test, y2_pred, target_names=['not malicous', 'malicous']))\n",
    "print(metrics.accuracy_score(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0's and 1's in y_train dataset:\n",
      "0.0    679497\n",
      "1.0    572636\n",
      "Name: x, dtype: int64\n",
      "\n",
      "CONFUSION MATRIX FOR TRAINING SET: \n",
      " [[672101   7396]\n",
      " [  4365 568271]]\n",
      "\n",
      "Number of 0's and 1's in y_test dataset:\n",
      "0.0    679498\n",
      "1.0    572636\n",
      "Name: x, dtype: int64\n",
      "\n",
      "CONFUSION MATRIX FOR TESTING SET: \n",
      " [[672016   7482]\n",
      " [  4204 568432]]\n"
     ]
    }
   ],
   "source": [
    "# part h) Confusion Matrices\n",
    "\n",
    "# SELECT K BEST FEATURE SELECTION\n",
    "# confusion matrices for training and testing set\n",
    "\n",
    "print(\"Number of 0's and 1's in y_train dataset:\")\n",
    "print(y2_train['x'].value_counts())\n",
    "print(\"\\nCONFUSION MATRIX FOR TRAINING SET: \\n {}\".format(confusion_matrix(y2_train, y2_tr_pred)))\n",
    "\n",
    "print(\"\\nNumber of 0's and 1's in y_test dataset:\")\n",
    "print(y2_test['x'].value_counts())\n",
    "print(\"\\nCONFUSION MATRIX FOR TESTING SET: \\n {}\".format(confusion_matrix(y2_test, y2_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAElCAYAAADp4+XfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de7xUdb3/8dcbNggKmoqVgoAXVMC7hNrVo2nqSawOKmYXirQs8pyjWVqdUrse83TxqD+zjsfsIpCVWkfTstQsFTHRQFMRLyAmeEFFkevn98f3u2H2MDN79t7MbPZe7+fjsR97ZtZ3rfVZa9asz7p+liICMzMrrj7dHYCZmXUvJwIzs4JzIjAzKzgnAjOzgnMiMDMrOCcCM7OCcyKwbiNpoKRfS3pR0s+7O55qJN0g6cOd6O9tkh5qREybMknDJS2T1Le7Y6mHpEMkLayz7TmSftLomJrNiaBJJD0uaXn+gfxD0hWSBpW1ebOkP0h6Oa8cfy1pTFmbLSV9V9KTeVjz8vshVcYrSadJmiPpFUkLJf1c0l6NnN46TQTeAGwbEcd1dWAd+UF3REQcFRE/qmP8IWnXkv7+FBG7d3R8eWWzKn+/SyX9RdLBHR1Od4mIJyNiUESs2djDzvP4GUktJZ+1SFosyTdFdZITQXMdExGDgH2B/YCzWzvkH/pNwLXADsBOwH3AnyXtnNv0B24GxgJHAlsCbwaeA8ZXGef3gH8FTgO2AXYDrgH+uaPBl/74NpIRwMMRsXoTiGVTMz0vK0OAPwIN2WPqofNxKXBUyfujgRe6KZbeISL814Q/4HHgnSXvzwf+r+T9n4BLKvR3A3Blfv0x4BlgUJ3jHAWsAcbXaHML8LGS95OB20veB/Ap4BHgMeBS4IKyYVwLnJ5f7wD8AliS259WZbznAiuBVcAyYAppw+SLwBPAYuBKYKvcfmSOZQrwJHBbhWEeAiysMr6t8vCW5OF/EeiTu/UF/gt4Nsc8NY+rpXweAbsCtwIv5vbT8+e35X5eydNzQnk8wI7AL3MMzwEXVYn1HOAnJe/H5GFvV/LZu4HZpJXiX4C9S7rtD9wLvExKINOBr5bOI+BzwD+AH9cxvM8BT+XhPQQclj8fD8wCXiItl98u+65a598OwHXA88A84OSyaZ2Rv5uXgbnAuBrLa+Tv7ucln10NfAGIks9qjXMgcAUpeTwAnFn2PVVdhsu/m97y1+0BFOWPkkQADAP+Bnwvv9+ctML+pwr9fQR4Or+eBvyoA+P8BPBEO21uof1E8DvS3sRA4O3AAkC5+9bA8vzj6QPcA3wJ6A/sDMwH3lVl3G1+VMBH8492Z2AQaaXZuqJqXblcCWwBDKwwvEOongiuJCWswXlYDwNTSubTA/l72Rr4PdUTwVV5pdMHGAC8tWxe7VopHlKyuQ/4To6/Tb/V5kuej98kJZ3WePYnJcoD83A/nJevzXL7J0h7gf2A95ESbmkiWA38Z24/sJ3h7Z6/7x1Kvodd8us7gA/m14OAg8q+q9Z4bwUuydO8L2kFe1jJtL5G2qrvC3wDuLPG8hrAnqTE87r890z+LEra1RrnN0kbXtuQkvOcku+p5jJML00EPjTUXNdIepn0w1oMfDl/vg1pAXy6Qj9Pkw4PAGxbpU01HW1fzTci4vmIWE76AQXwttxtInBHRCwC3kTaaj0vIlZGxHzgB8CkOsdzEmmrcn5ELCMdOptUdvjinIh4JcdSl3zS8gTg7Ih4OSIeJ+0BfDA3OZ6UlBdGxAukFUU1q0iHtHaIiNci4vY6wxhPSpZn5vjb6/d4SUtJSfZkYGKsP4R2MvD9iLgrItZEOn+xAjgo/7UAF0bEqoj4JTCzbNhrgS9HxIo8H2sNbw0pIYyR1C8iHo+IR0vmxa6ShkTEsoi4s3wiJO0IvBX4XJ7m2cAPWT/vIW14XB/pnMKPgX3amZevAb8mfaeTSFv+r3VgnMcDX8vL9ALgwpJhd3UZ7pGcCJrrPRExmLRVtgfrV/AvkH6c21foZ3vS1iCkwwmV2lTT0fbVLGh9EWmzaBpwYv7o/cBP8+sRwA75BOfSvCL7POmEcD12IG3NtnqCtFIr7X8BHTeE9VvKpcMeWjLe0uHWGsdnAQEzJc2V9NE6Y9iRtHdW7/mQGRHxOtK0zwEOKOk2AjijbD7vmKdjB+Cp/D1Vm54lEfFayfuqw4uIecC/kbaEF0uaJmmH3N8U0jmnv0u6W9K7K0zHDsDzEfFyyWel8x7SIapWrwID6jh3cSXwofx3ZQfHWf59ly4XXV2GeyQngm4QEbeSjlFekN+/QtrNrnTlzPGkE8SQDlm8S9IWdY7qZmCYpHE12rxCOjTV6o2VQi57fxUwUdII0uGEX+TPFwCPRcTrSv4GR8TRdca7iPRDbDWcdBjjmRqx1ONZ1m/Jlw77qfz6adJhoVY7VhtQRPwjIk6OiB2AjwOXlF4pVMMCYHhHT85GxLN5POdIak3qC0hbtKXzefOIuCpPy1BJqjE95fOw1vCIiJ9FxFtJ8y9Ih5WIiEci4kTg9fmzqyssm4uAbSQNLvmsdN531p9IGzlvAMr3rNob59O0nSfDS153dRnukZwIus93gcMl7ZvfnwV8OF/qOVjS1pK+ChxMOrEKabd5AfALSXtI6iNpW0mfl7TBghoRj5COk16VL63sL2mApEmSzsrNZgPvk7R5XqFNaS/wiLiXdMz1h8CNEbE0d5oJvCTpc/kegb6S9pT0pjrnyVXAv0vaKV9a+3XSydgOXVWUp3HdH2lvawbwtTxvRwCnA63Xg88A/lXSUEmvI50crTbs4yS1Jo0XSCvG1ssknyEdU65kJmkF9E1JW+TY3lLP9ETE34EbSXsjkA5VfELSgfny4C0k/XNe8d2R45maL6s8lupXlLWqOjxJu0s6VNJmpMMvy1unV9IHJG0XEWtJJ5kpmRetsS8gnXz+Rp7mvUnL2E/pgrzHcwwwoWzvp55xzgDOzr+xYcCnS3rv6jLcIzkRdJOIWELapf2P/P524F2kk3tPk3ZX9yOdUHwkt1kBvBP4O+kE7kukBXcIcFeVUZ0GXARcTPqxPgq8l3SMFdLJy5WkldiPqP8HelWO5Wcl07SG9OPcl3S1xbOkZLFVncO8nJTsbsv9v0bbH2k9hpJWVqV/u+ThvEI68Xd7jvvy3M8PSJfu3k+62uZ60p5Ipevg3wTcJWkZ6dj0v0bEY7nbOcCP8iGF40t7Kpk3u5KuelpIOsZdr28Bp0h6fUTMIh3Xv4iUjOaRTvITEStJy9AU0vf9AeA3pGP+FdUaHun8QOvJ6n+Qtv4/n7sdCczN8+J7wKSyQ06tTiSdQF4E/Ip0fuJ3HZj2anHPjYi5VTrXGue5pN/XY6Tv/cclw+zqMtwjqSyZmhWepKOASyNiRLuNewBJd5Gm53+7OxbbNHmPwAovHwI4Oh9KGUq6mutX3R1XZ0l6h6Q35un5MLA38Nvujss2XU4EZukqoHNJh0XuBR4kXUfeU+1OumfhReAM0qWnG+MyYuulfGjIzKzgvEdgZlZwTgQdlC/V/GF+PVKpGmJLft9uuWJtoiV6Jd0i6WPdHUdPoQZVOi0Z/qWS/qPk/alKVTeX5UuGlykXI7Sua9T3qR5SirzQiUBlZYPzZ+vqjVdaOCLi6xFRcYUZdZQrjsaW6B0m6ReSnlUqY/03SZM39nhqjL/dWu1K5bjfWfJ+kqQXJL2jQttDJK3NK71lkp6SdG55u07EWdePXtJ4Sdfny0GflzRT0ke6Ov56RMQnIuIrOY5+wLeBI/Ky81z+P39jjEvSZElrSubzMkkXbYThNn3jQtIUSX9XKuX+jKT/U9sbyxo9/o1SirzZCp0IeqHWG85GkOoMfYi2d+VuUvLe08XAP+e7rStZlFd6g0j1Y6ZIek8TYjsY+AOpeNmupPl5Km3LHzfLG0jF06pdM183Vb+z+Y7W+Zz/pnZ1XF1VI9Zq7d9BugnxxFzKZTTp5jFrT2wCle+664+yapFRUl2QVCFyOemu1GX5bwfaVoYcSfUqlfeV9LcstzukSj9fAf5MKsN7EzCkJJ4PkW5+eY5089njlJSzLot9GbBvjek9iHTH5dIc3yEl3dbFnt9/lHT1zAuku1pHlHQbS7qh7XlSovk86eai0rLS91WJ4XHSjWinkG7WqVVy+BDKqomSftifL3m/R0ksDwHHl3Q7mlRV9GVSeYHPVPteK4z7duDiemMj3Rn+aB7XA8B7S7pVK10t0g19i3O3+4E9c7crgK+Savm8kpeZZcAfypdd0k1fF5BuVHuGVCp8YGmclJWdLpuWyZRUnC3rVmvYW5NuVluSl5PfAMNyt6+Rbsh7Lcd9EWXLfoXfzGTS7+A7+ftsrZhadVksi/UzwDU1vrN251NJ21qlqPuSlvnW7/seUsmKekqRj87TvJSU2CeUdLuCtGH0f3m4d5ErvTZ8XdiMkWyqf9RIBJUWjgrd2yzYlK1MS/o5hXQ38JZV+nmU9IMfmN9/M3cbkxeot5KKpl1AWtFWSwS/zz+kScDwsm5DScnkaNKe4OH5/XblsQPvId1dOppU9O2LwF9yt8GkO5/PIG2lDgYOLJ83Neb54/kH9gywTztty39Eo0gr9EPz+y1Ie0AfyXHuT1rRjs3dnwbell9vDexf7XstG2/VsuA1YjuO9aW4TyCtDLbP3SqWribdSX4PqZSy8vxu7ecK1q8I2ywz5csuqVzJdaQqtoNJd41/oyTONmWnK0zLZKonglrD3hb4lzy/BpOefXBNSb/rlqka07GuTY5jNeku8BbS76Hqslgh1reRkvy5wFuAzTowLeu+T9ovRX0mqYz87vl724f0lL0230uF4fbL0/L5PNxDSSv83Uu+8+dJJUFaSHf5T2vKurAZI9lU/8q/tPzZOWzEREBaiS8GdqvRzxdL2n8S+G1+/SXgqpJum5O2uqslgq1J5QDmklZks4E35W6fo2xrkLR19eHy2EkPw5lS0q4PqSrkCNKt+/dWGf+6eVNjnj9OKo1xLfnBMDXaHkLacl+a+wnSMwr65+4nAH8q6+f7pHICkLb8Pg5sWWG4tRLB0DyuPdqJrdYwZgPH5tdXApeRt5ZL2hxKei7CQeXzgjoTAWlF9AolW46k+lSPlcS5EhhQI9bJpBXw0pK/g9obdoXh7Au8UPJ+3TJVYzpKl7vJwJNlw6y6LFaJ4SjSCn4paSPq26Qt+HrmU+sK+8AKcZwN/G9+/VDrd1th/LUSwdtIe2V9SrpfRSqt3vqd/7Ck29HA32v9RjbWX9HPEawhZelS/Uhb3V2mVBd9Bmll+3CNpuVleFufZdymXG5EvEraiq8oIl6IiLMiYizpuPJs0jMQRFqJH6e25XXfSuUy1SOA75W0e570QxpK2gV+tEI/HfEJ0h7QD3NstSyKVAFyS9KW83JSTaTWOA8sm6aTWF9B9V9IP6YnJN2q+p/7W6sseEWSPiRpdkkce7K+zHjF0tUR8QfW14F6RtJlkrasd5zZdqQNhHtKxv3b/Hmr8rLTldwZbStu3tnesJUKFX5f0hOSXiIdGnldF6+IKy+ZXWtZ3EBE3BARx5C2+o8lJZePtTctFcZZqxR1Z38DOwALIhXpa9VeSe42zzVvlKIngidJWymldmJ9ffLo7IAlDSQ9G/i7EXFDJwfTpjxyHua29fQYqXzxBaSFbxvSD+zHZT/2LSKi0kNYFgAfL2s7MCL+krvtUm20dU7XYuAw0hbSJXX2Q0S8SCoWd0xJnLeWxTkoIk7N7e+OiGNJhdKuYf2Jw5px5oR7BymRtEupmukPSI+43DbScwTmkFZYRI3S1RFxYUQcQDrvshvpsENHPEtKjmNL5sFWkU6ur5ukDg6z3mGfQTo8cmBO1G/Pn7cm9/LxvpL/1yp7Xt5PrWWxqohYGxE3k07471nHtJSP87GoXoq61m+glkXAjpJK17sboyR3lxU9EUwHvpgvu+yTL2s8hvQMVEjHsbeV1JnKg5eTduvO70J8VwPHSHqz0oPrz2X9j2wDkv5TqWRuS75k7lRgXkQ8RzoBfoykdymV1h2QL6McVmFQl5LK9I7Nw91KUuuzEn4DvFHSv0naTKlU8YG52zPAyLIFvaJITzQ7FDhS0nfqmRlKpaknsf7qmd8Au0n6oKR++e9NkkYrldw+SdJWEbGKdGiptFx0e9/rZ4HJks6UtG0e/z6SplVouwVpBbYkt/sIaeXTGnfF0tU51gPz5aGvkE6sduiy4rx1+QPgO5Jen8c3VNK7OjKcTg57MGnlulTSNqx/4l6rNmW5I1XcfQr4QF4GP0r7K9Ray2Ibko5Vuhx5ayXjgXeQ9nY6Mp/aK0X9Q+Arkkbl8ezduoyUT3OZu0jf82fzsnoIaX1TaZlqqqIngvNIV9HcTvqBng+cFBFzYF0d+KuA+XkXcYeqQ9rQJOC9antt9tva7atEpBK7nyYtKE+TTiwtpnpJ4c1JxdKWkk5ujQAm5GEtIO0qf560wlpA2vrcYBmIiF+RTi5Oy7v8c8iXTUZ66tPhpAX4H6SH2v9T7vXn+f9zkv5ax/QtICWDiZK+UaXZDq3zj7Sntg3p8E9rLEeQ5vWiHE/rSVFIjyZ8PE/DJ0glmev6XvMW56H5b76k50nH+a+v0PYB0qMv7yCtCPYinbRvVa109ZakldMLrL8y7IJa86yKz5FOQt6Zp/X3pC31jaHWsL9LOqH7LHAnGxa2+x7pu31BUuvjIE8mLXfPkfaC2tuyr7osVvBCHv4jpMT/E+BbEdFaWr2u+RTtl6L+Nmnv8qY8nv/J8wFqlyJfSfo9HpWHeQnwobw8divXGupB8hbxUmBUrK+Bb2bWJUXfI9jkSTomn5TbgrS1+DfSlTdmZhuFE8Gm71jSYY9FpOvoJ4V348xsI/KhITOzgvMegZlZwXWoqNOmYMiQITFy5MjuDsPMrEe55557no2ISjfQ9bxEMHLkSGbNmtXdYZiZ9SiSnqjWzYeGzMwKzonAzKzgnAjMzArOicDMrOCcCMzMCq5hiUDS5ZIWS5pTpbskXShpnqT7Je3fqFjMzKy6Ru4RXEF6jm01R5FKJowiPcrx/zUwFjMzq6Jh9xFExG2SRtZocixwZa6bc6ek10naPiKeblRMjbBmbbBqzdr8F6xes5bVa4M1ayP/T+9Xr4mStun/6rVrWbk6WL12be62vv2a3E9nCoA0s2xIZ0fVuSnr3Pg6Ozd6wrR1VmeXEc//8nF1Uicn7rDRb2CfHV/X2bFW1Z03lA2l7WPpFubPNkgEkk4h7TUwfPjwjTLyF19dxX0Ll/Lk86/y4vJVvLR8Fa+sXM2rK9bw6so1vLJyNa+tWsOK1WtZsWotK1an1yvz34q88nepJjPrjHYf0lrB67cc0OsSQaXZUHG1GhGXkR4Kwrhx47q06l25ei1fv/5BfnrXE6xas35Q/Vv6MGizFgb265v+9++bXm/RwmYtfenf0ofNWvrQv/Svbx/69e1DS1/Rv28fWvqIlr596NdX9O2T3vfto3X/+/YR/XI//fpqXb/9Wvvt04e+fUW/kvbqzNJC5xayzo2JzsfY6fF1ZlzNm49d0ROmrTO99YRlJPXX5C98E9GdiWAh6SHQrYaRSi031Jevm8NVMxfw/gOH8+69t2fnIYPYeot+bNbSledtm5n1XN2ZCK4DpuZnwB4IvNjo8wNzF73IVTMX8PF37MzZR41u5KjMzHqMhiUCSVcBhwBDJC0kPdi6H0BEXEp69uvRpGeIvgp8pFGxtLr6noX0b+nDJw/ZtdGjMjPrMRp51dCJ7XQP4FONGn8ld85/ngN32oatBvZr5mjNzDZphbmzOCKYv2QZe7xxcHeHYma2SSlMIlj66ipWrF7LG7ca2N2hmJltUgqTCJ5/dSUA227Rv5sjMTPbtBQmEby0fBWAzw+YmZUpTCJYvmoNAAP7+34BM7NShUkEK1avBWCzlsJMsplZXQqzVlyxqjUReI/AzKxUcRLB6nRoqL/3CMzM2ijcWrFPMWtKmZlVVbhEYGZmbTkRmJkVnBOBmVnBORGYmRWcE4GZWcEVJhH42cJmZpUVJhG0KuozSc3MqilcIjAzs7acCMzMCs6JwMys4JwIzMwKrjCJIPBlQ2ZmlRQmEbTyNUNmZm0VLhGYmVlbTgRmZgXnRGBmVnBOBGZmBedEYGZWcIVJBC46Z2ZWWWESQSvXnDMza6twicDMzNpyIjAzK7iGJgJJR0p6SNI8SWdV6D5c0h8l3SvpfklHNzIeMzPbUMMSgaS+wMXAUcAY4ERJY8qafRGYERH7AZOASxoVj5mZVdbIPYLxwLyImB8RK4FpwLFlbQLYMr/eCljUqGB81ZCZWWWNTARDgQUl7xfmz0qdA3xA0kLgeuDTlQYk6RRJsyTNWrJkSZeCksvOmZm10chEUGmNW75dfiJwRUQMA44Gfixpg5gi4rKIGBcR47bbbrsGhGpmVlyNTAQLgR1L3g9jw0M/U4AZABFxBzAAGNLAmMzMrEwjE8HdwChJO0nqTzoZfF1ZmyeBwwAkjSYlgq4d+zEzsw5pWCKIiNXAVOBG4EHS1UFzJZ0naUJudgZwsqT7gKuAyRE+rWtm1kwtjRx4RFxPOglc+tmXSl4/ALylkTGYmVlthbmz2LsZZmaVFSYRtHLROTOztgqXCMzMrC0nAjOzgnMiMDMrOCcCM7OCcyIwMyu4wiQC36dmZlZZYRKBmZlV5kRgZlZwTgRmZgXnRGBmVnBOBGZmBVeYROBrhszMKitMImjlonNmZm0VLhGYmVlbTgRmZgXnRGBmVnBOBGZmBedEYGZWcMVJBL5+1MysouIkgky+ftTMrI26E4GkzRoZiJmZdY92E4Gk8ZL+BjyS3+8j6b8bHpmZmTVFPXsEFwLvBp4DiIj7gH9qZFBmZtY89SSCPhHxRNlnaxoRjJmZNV9LHW0WSBoPhKS+wKeBhxsb1sYXvmzIzKyievYITgVOB4YDzwAH5c96JF8zZGbWVj17BKsjYlLDIzEzs25Rzx7B3ZKul/RhSYMbHpGZmTVVu4kgInYBvgocAPxN0jWS6tpDkHSkpIckzZN0VpU2x0t6QNJcST/rUPRmZtZldd1QFhF/iYjTgP2Bl4CfttdPPrF8MXAUMAY4UdKYsjajgLOBt0TEWODfOha+mZl1VT03lA2SdJKkXwMzgSXAm+sY9nhgXkTMj4iVwDTg2LI2JwMXR8QLABGxuEPRm5lZl9VzsngO8Gvg/Ij4UweGPRRYUPJ+IXBgWZvdACT9GegLnBMRvy0fkKRTgFMAhg8f3oEQ1gtfPWpmVlE9iWDniFjbiWFXulKzfHXcAowCDgGGAX+StGdELG3TU8RlwGUA48aN69Iq3TXnzMzaqpoIJP1XRJwB/ELSBivfiHhfO8NeCOxY8n4YsKhCmzsjYhXwmKSHSInh7nqCNzOzrqu1RzA9/7+ok8O+GxglaSfgKWAS8P6yNtcAJwJXSBpCOlQ0v5PjMzOzTqiaCCJiZn45OiLaJANJU4Gbaw04IlbndjeSjv9fHhFzJZ0HzIqI63K3IyQ9QKpfdGZEPNf5yTEzs46q5xzBR9lwr2BKhc82EBHXA9eXffalktdBKl9xeh1xmJlZA9Q6R3AC6XDOTpJ+WdJpMLC0cl9mZtbT1NojmEl6BsEw0o1hrV4G7m1kUI3gq0fNzCqrdY7gMeAx4PfNC6fx5PqjZmZt1Do0dGtEvEPSC7TdoBbp8P42DY/OzMwartahodbHUQ5pRiBmZtY9qtYaKrmbeEegb0SsAQ4GPg5s0YTYzMysCeqpPnoN6TGVuwBXAqMBl4s2M+sl6kkEa3MJiPcB342IT5MKyvUoLjpnZlZZPYlgtaTjgA8Cv8mf9WtcSI3lonNmZm3Vkwg+SjpxfH5EzM+1g65qbFhmZtYs7ZaYiIg5kk4DdpW0B+lhM19rfGhmZtYM7SYCSW8DfkyqICrgjZI+GBF/bnRwZmbWePUUnfsOcHREPAAgaTQpMYxrZGBmZtYc9Zwj6N+aBAAi4kGgf+NCMjOzZqpnj+Cvkr5P2gsAOIkeWXTO14+amVVSTyL4BHAa8FnSOYLbgP9uZFCN5KtHzczaqpkIJO0F7AL8KiLOb05IZmbWTFXPEUj6PKm8xEnA7yR9tGlRmZlZ09TaIzgJ2DsiXpG0HemRk5c3JywzM2uWWlcNrYiIVwAiYkk7bc3MrIeqtUewc8mzigXsUvrs4oh4X0MjMzOzpqiVCP6l7P1FjQyk0Vx91MysslrPLL65mYE0ja8fNTNrw8f9zcwKzonAzKzg6k4EkjZrZCBmZtY92k0EksZL+hvwSH6/j6QeW2LCzMzaqmeP4ELg3cBzABFxH+mJZT2KLxoyM6usnkTQJyKeKPtsTSOCaQb5siEzszbqqT66QNJ4ICT1BT4NPNzYsMzMrFnq2SM4FTgdGA48AxyUPzMzs16g3UQQEYsjYlJEDMl/kyLi2XoGLulISQ9JmifprBrtJkoKSX78pZlZk9Xz8PofUOFca0Sc0k5/fYGLgcOBhcDdkq4rfexlbjeY9OCbuzoQt5mZbST1HBr6PXBz/vsz8HpgRR39jQfmRcT8iFgJTAOOrdDuK8D5wGt1RWxmZhtVu3sEETG99L2kHwO/q2PYQ4EFJe8XAgeWDWs/YMeI+I2kz1QbkKRTgFMAhg8fXseoK3DVOTOzijpTYmInYEQd7Spdp7lubSypD/Ad4Iz2BhQRl0XEuIgYt91229UdaMWgfPWomVkb9ZwjeIH1K/A+wPNA1RO/JRYCO5a8HwYsKnk/GNgTuEVp7fxG4DpJEyJiVh3DNzOzjaC9h9cL2Ad4Kn+0NqLuYyx3A6Mk7ZT7nwS8v7VjRLwIDCkZ1y3AZ5wEzMyaq+ahobzS/1VErMl/dR9oj4jVwFTgRuBBYEZEzJV0nqQJXYrazMw2mnruLJ4paf+I+GtHBx4R15Meel/62ZeqtD2ko8M3M7Ouq5oIJLXkrfq3AidLehR4hXQSOCJi/ybFuFH4miEzs8pq7RHMBPYH3tOkWJrCFw2ZmbVVKxEIICIebVIsZmbWDWolgu0knV6tY0R8uwHxmJlZk9VKBH2BQfhoiplZr1YrETwdEec1LRIzM+sWte4j8FhuFrQAAA6ZSURBVJ6AmVkB1EoEhzUtiiZwzTkzs8qqJoKIeL6ZgTSLXHXOzKyNzlQfNTOzXsSJwMys4JwIzMwKzonAzKzgnAjMzAquMImgA49SMDMrlMIkgla+eNTMrK3CJQIzM2vLicDMrOCcCMzMCs6JwMys4AqTCHzNkJlZZYVJBK1cc87MrK3CJQIzM2vLicDMrOCcCMzMCs6JwMys4JwIzMwKrjCJwDXnzMwqK0wiaCWXnTMza6NwicDMzNpqaCKQdKSkhyTNk3RWhe6nS3pA0v2SbpY0opHxmJnZhhqWCCT1BS4GjgLGACdKGlPW7F5gXETsDVwNnN+oeMzMrLJG7hGMB+ZFxPyIWAlMA44tbRARf4yIV/PbO4FhDYzHzMwqaGQiGAosKHm/MH9WzRTghkodJJ0iaZakWUuWLOlUML5oyMysskYmgkqX51RcH0v6ADAO+Fal7hFxWUSMi4hx22233caPysyswFoaOOyFwI4l74cBi8obSXon8AXgHRGxooHxmJlZBY3cI7gbGCVpJ0n9gUnAdaUNJO0HfB+YEBGLGxiLmZlV0bBEEBGrganAjcCDwIyImCvpPEkTcrNvAYOAn0uaLem6KoMzM7MGaeShISLieuD6ss++VPL6nY0cv5mZtc93FpuZFVxhEkG46pyZWUWFSQSt/MxiM7O2CpcIzMysLScCM7OCcyIwMys4JwIzs4JzIjAzKzgnAjOzgitcIvDVo2ZmbRUuEZiZWVtOBGZmBedEYGZWcE4EZmYFV5hE4JpzZmaVFSYRtJKrzpmZtVG4RGBmZm05EZiZFZwTgZlZwTkRmJkVnBOBmVnBtXR3AM0S+PpRs+62atUqFi5cyGuvvdbdofRaAwYMYNiwYfTr16/ufgqTCFr54lGz7rNw4UIGDx7MyJEjfSl3A0QEzz33HAsXLmSnnXaquz8fGjKzpnnttdfYdtttnQQaRBLbbrtth/e4nAjMrKmcBBqrM/PXicDMrOCcCMysUPr27cu+++7LnnvuyTHHHMPSpUvXdZs7dy6HHnoou+22G6NGjeIrX/kKUVKo7IYbbmDcuHGMHj2aPfbYg8985jMVx1Fvu02FE4GZFcrAgQOZPXs2c+bMYZtttuHiiy8GYPny5UyYMIGzzjqLhx9+mPvuu4+//OUvXHLJJQDMmTOHqVOn8pOf/IQHH3yQOXPmsPPOO28w/HrbVbNmzZqNM6EdUJirhlx91GzTcu6v5/LAopc26jDH7LAlXz5mbN3tDz74YO6//34Afvazn/GWt7yFI444AoDNN9+ciy66iEMOOYRPfepTnH/++XzhC19gjz32AKClpYVPfvKTGwyzVrvJkyfz7ne/m4kTJwIwaNAgli1bxi233MK5557L9ttvz+zZsznmmGMYMWLEuv7OOeccBg8ezBlnnMG3vvUtZsyYwYoVK3jve9/Lueee28m5tV7h9gh8nsrMIG1533zzzUyYMAFIh4UOOOCANm122WUXli1bxksvvcScOXM26F5Jve3KzZw5k6997Ws88MADTJo0ienTp6/rNmPGDI477jhuuukmHnnkEWbOnMns2bO55557uO222zo8rnKF2SMws01LR7bcN6bly5ez77778vjjj3PAAQdw+OGHA+ka/GpX3DTjSqfx48evu/Z/v/32Y/HixSxatIglS5aw9dZbM3z4cC688EJuuukm9ttvPwCWLVvGI488wtvf/vYujbuhewSSjpT0kKR5ks6q0H0zSdNz97skjWxkPGZmrecInnjiCVauXLnuHMHYsWOZNWtWm7bz589n0KBBDB48mLFjx3LPPfe0O/xa7VpaWli7di2QEs/KlSvXddtiiy3atJ04cSJXX30106dPZ9KkSev6Ofvss5k9ezazZ89m3rx5TJkypf6Jr6JhiUBSX+Bi4ChgDHCipDFlzaYAL0TErsB3gP9sVDxmZqW22morLrzwQi644AJWrVrFSSedxO23387vf/97IO05nHbaaXz2s58F4Mwzz+TrX/86Dz/8MABr167l29/+9gbDrdVu5MiR65LEtddey6pVq6rGN2nSJKZNm8bVV1+97pzCu971Li6//HKWLVsGwFNPPcXixYu7PC8auUcwHpgXEfMjYiUwDTi2rM2xwI/y66uBw+S7TcysSfbbbz/22Wcfpk2bxsCBA7n22mv56le/yu67785ee+3Fm970JqZOnQrA3nvvzXe/+11OPPFERo8ezZ577snTTz+9wTBrtTv55JO59dZbGT9+PHfdddcGewGlxo4dy8svv8zQoUPZfvvtATjiiCN4//vfz8EHH8xee+3FxIkTefnll7s8HxQNupxG0kTgyIj4WH7/QeDAiJha0mZObrMwv380t3m2bFinAKcADB8+/IAnnniiw/H87oFnuObep/iv4/dhQL++nZ0sM+uCBx98kNGjR3d3GL1epfks6Z6IGFepfSNPFlfasi/POvW0ISIuAy4DGDduXKcy1+Fj3sDhY97QmV7NzHq1Rh4aWgjsWPJ+GLCoWhtJLcBWwPMNjMnMzMo0MhHcDYyStJOk/sAk4LqyNtcBH86vJwJ/iEYdqzKzTYJ/4o3VmfnbsEQQEauBqcCNwIPAjIiYK+k8SRNys/8BtpU0Dzgd2OASUzPrPQYMGMBzzz3nZNAgrc8jGDBgQIf6a9jJ4kYZN25clF/ra2Y9g59Q1njVnlDWXSeLzcza6NevX4eenGXNUbhaQ2Zm1pYTgZlZwTkRmJkVXI87WSxpCdDxW4uTIcCz7bbqXTzNxeBpLoauTPOIiNiuUocelwi6QtKsamfNeytPczF4mouhUdPsQ0NmZgXnRGBmVnBFSwSXdXcA3cDTXAye5mJoyDQX6hyBmZltqGh7BGZmVsaJwMys4HplIpB0pKSHJM2TtEFFU0mbSZqeu98laWTzo9y46pjm0yU9IOl+STdLGtEdcW5M7U1zSbuJkkJSj7/UsJ5plnR8/q7nSvpZs2Pc2OpYtodL+qOke/PyfXR3xLmxSLpc0uL8BMdK3SXpwjw/7pe0f5dHGhG96g/oCzwK7Az0B+4DxpS1+SRwaX49CZje3XE3YZr/Cdg8vz61CNOc2w0GbgPuBMZ1d9xN+J5HAfcCW+f3r+/uuJswzZcBp+bXY4DHuzvuLk7z24H9gTlVuh8N3EB6wuNBwF1dHWdv3CMYD8yLiPkRsRKYBhxb1uZY4Ef59dXAYZIqPTazp2h3miPijxHxan57J+mJcT1ZPd8zwFeA84HeUPe4nmk+Gbg4Il4AiIjFTY5xY6tnmgPYMr/eig2fhNijRMRt1H5S47HAlZHcCbxO0vZdGWdvTARDgQUl7xfmzyq2ifQAnReBbZsSXWPUM82lppC2KHqydqdZ0n7AjhHxm2YG1kD1fM+7AbtJ+rOkOyUd2bToGqOeaT4H+ICkhcD1wKebE1q36ejvvV298XkElbbsy6+RradNT1L39Ej6ADAOeEdDI2q8mtMsqQ/wHWByswJqgnq+5xbS4aFDSHt9f5K0Z0QsbXBsjVLPNJ8IXBER/yXpYODHeZrXNj68brHR11+9cY9gIbBjyfthbLiruK6NpBbS7mStXbFNXT3TjKR3Al8AJkTEiibF1ijtTfNgYE/gFkmPk46lXtfDTxjXu2xfGxGrIuIx4CFSYuip6pnmKcAMgIi4AxhAKs7WW9X1e++I3pgI7gZGSdpJUn/SyeDrytpcB3w4v54I/CHyWZgeqt1pzodJvk9KAj39uDG0M80R8WJEDImIkRExknReZEJE9OTnnNazbF9DujAASUNIh4rmNzXKjaueaX4SOAxA0mhSIljS1Cib6zrgQ/nqoYOAFyPi6a4MsNcdGoqI1ZKmAjeSrji4PCLmSjoPmBUR1wH/Q9p9nEfaE5jUfRF3XZ3T/C1gEPDzfF78yYiY0G1Bd1Gd09yr1DnNNwJHSHoAWAOcGRHPdV/UXVPnNJ8B/EDSv5MOkUzuyRt2kq4iHdobks97fBnoBxARl5LOgxwNzANeBT7S5XH24PllZmYbQW88NGRmZh3gRGBmVnBOBGZmBedEYGZWcE4EZmYF50RgvYKkNZJml/yNrNF2ZLXKjh0c5y25KuZ9uaTD7p0YxickfSi/nixph5JuP5Q0pqtxmrWn191HYIW1PCL27YbxnhQRsySdQrpXo0P3ZuTrwltNBuaQ7xKNiI9trCDNavEegfVaecv/T5L+mv/eXKHNWEkz817E/ZJG5c8/UPL59yX1bWd0twG75n4Py7Xx/5Zry2+WP/+m1j8T4oL82TmSPiNpIqkG1E/zOAfmPY5xkk6VdH5JzJMl/Xcn4zTbgBOB9RYDSw4L/Sp/thg4PCL2B04ALqzQ3yeA7+W9iXHAwlym4ATgLfnzNcBJ7Yz/GOBvkgYAVwAnRMRepL3uUyVtA7wXGBsRewNfLe05Iq4GZpH2MPaNiOUlna8G3lfy/gRgeifjNNuADw1Zb1Hp0FA/4CJJrSvJ3Sr0dwfwBUnDgF9GxCOSDgMOAO7O5TgGkpJKJT+VtBx4nFT+eHfgsYh4OHf/EfAp4CLSMxF+KOn/gLpLY0fEEknzc12ZR/I4/pyHW2+cZlU5EVhv9u/AM8A+pL3fDR5OExE/k3QX8M/AjZI+Rirz+6OIOLuOcZxUWshOUsXnWuSaOeNJxdEmAVOBQzswLdOB44G/A7+KiFBa+9cbp1lVPjRkvdlWwNO5Lv0HSUXL2pC0MzA/Ii4kVXXcG7gZmCjp9bnNNqr/Gc9/B0ZK2jW//yBwq6RBwFYRcT3wb0ClE9svk8pnV/JL4D2k2vvT82ddidNsHe8RWG92CfALSccBfwReqdDmBNLTrVYB/wDOi4jnJX0RuEnpATerSIdhnmhvhBHxmqSPkKq8tpDKKF8KbANcm88hiLS3Uu4K4NJ8qOngsuG+kCuKjomImfmzBzobp1kpVx81Mys4HxoyMys4JwIzs4JzIjAzKzgnAjOzgnMiMDMrOCcCM7OCcyIwMyu4/w/idYuz6KhgMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part h) ROC curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logreg2_roc = logreg2.predict_proba(x2_test)\n",
    "\n",
    "false_pos, true_pos, throwaway= roc_curve(y2_test, logreg2_roc[:, 1])\n",
    "\n",
    "plt.plot(false_pos, true_pos, label='ROC Curve')\n",
    "plt.xlabel('False Positive')\n",
    "plt.ylabel('True Positive')\n",
    "plt.title(\"ROC Curve for Logistic Regression Model\\nUtilizing Select K Best Classifier Feature Selection\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
